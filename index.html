<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modelagem Acústica e Estimação de Parâmetros</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

 <!-- Cabeçalho e navegação -->
    <header>
        <h1>Bem-vindo ao nosso site</h1>
        <nav>
            <!-- Botões para trocar de idioma -->
            <button onclick="translate('en')">English</button>
            <button onclick="translate('de')">Deutsch</button>
        </nav>
    </header>

    <header>
        <h1>Modelagem Acústica, Processamento de Sinais de Áudio e Processamento de Imagens</h1>
        <nav>
            <ul>
                <li><a href="#sobre">Sobre</a></li>
                <li><a href="#dissertacao">Dissertação</a></li>
                <li><a href="#projetos">Projetos</a></li>
                <li><a href="#artigos">Artigos publicados</a></li>
                <li><a href="#contato">Contato</a></li>
            </ul>
        </nav>
    </header>

    <section id="sobre">
        <h2>Sobre Mim</h2>
        <p>Olá! Meu nome é Luis Paulo Albuquerque Guedes, sou Capitão-Tenente da Marinha do Brasil. Sou bacharel em Ciências Navais pela Escola Naval (2015) e bacharel em Ciências Econômicas pela Universidade Católica de Brasília (2022). Tenho Especialização em Análise de Ambiente Eletromagnético pelo Instituto Tecnológico de Aeronáutica - ITA (2022) e em Sistemas de Defesa Eletrônica pela Pontifícia Universidade Católica do Rio de Janeiro - PUC-Rio (2021). Exerci função técnica de Encarregado da Seção de Planejamento e Prospecção em Guerra Acústica no Centro de Guerra Acústica e Eletrônica da Marinha (CGAEM), e funções operativas de Chefe de Departamento de Intendência, de Encarregado de Divisão de Sistemas de Armas e de Sistemas Eletrônicos, todas em navios da Marinha do Brasil. Atualmente, sou aluno de mestrado em Engenharia Elétrica, na área de Processamento de Sinais de Áudio, desenvolvida na COPPE/UFRJ, sob orientação da Professora Mariane Petráglia e do Professor Julio Cesar Boscher Torres.   
    Inicialmente, este repositório tem como objetivo reunir os registros de progresso da minha dissertação de mestrado.</p>

        <p>Meu curriculum vitae encontra-se disponível em: <a href="https://drive.google.com/uc?export=download&id=1bxuK9c2iCFkGVn5Ir6R0GLqEurPVsBQe" download><button>Baixar CV</button></a></p>
    </section>

    <section id="dissertacao">
        <h2>Dissertação</h2>
        <p>Confira os detalhes da versão final da dissertação: <a href="link-da-dissertacao" target="_blank">Acesse aqui</a>.</p>
    </section>

    <style>
        ul {
            padding-left: 0;
            list-style-position: inside;
        }
    </style>

    <section id="projetos">
        <h2>Meus Projetos</h2>

        <!-- Projeto 1 -->
        <div class="projeto">
            <h3><a href="link-projeto-1" target="_blank">Projeto 1</a></h3>
            <p>
                Trata-se de versão inicial da dissertação de mestrado sobre estimação de parâmetros acústicos usando modelos de Aprendizagem Profunda (Deep Learning). 
                Inicialmente, foram geradas 1000 salas com configur....

                PASSO 1:
                
                Inicialmente, as dimensões das salas foram definidas aleatoriamente dentro de um intervalo preestabelecido. O comprimento e a largura variaram entre 3 e 12 metros, enquanto a altura assumiu valores entre 2,5 e 4,5 metros. Esses valores foram arredondados para uma casa decimal para garantir maior precisão nas simulações.
                Além das dimensões, foram atribuídos coeficientes de difusão para cada superfície da sala. O mesmo valor foi aplicado uniformemente a todas as superfícies e foi sorteado dentro de um intervalo entre 0,2 e 1. Esse coeficiente foi gerado para seis superfícies distintas: quatro paredes, teto e chão. Os valores foram armazenados de acordo com a frequência correspondente, considerando seis faixas padronizadas: 125 Hz, 250 Hz, 500 Hz, 1000 Hz, 2000 Hz e 4000 Hz.
                Para determinar os coeficientes de absorção, foi utilizado um processo probabilístico apresentado em [COLOCAR LINK] a fim de definir perfis distintos para paredes, teto e chão. Em alguns casos, um único valor foi atribuído a todas as superfícies de um mesmo tipo, enquanto em outros, valores diferenciados foram gerados para cada frequência. Esses coeficientes foram estabelecidos a partir de intervalos que variaram conforme o tipo de superfície, refletindo as propriedades acústicas de materiais comuns.
                As paredes puderam apresentar coeficientes de absorção homogêneos ou diferenciados por frequência, variando entre valores baixos, típicos de materiais reflexivos, e valores mais elevados, condizentes com superfícies mais absorventes. O teto e o chão seguiram uma lógica semelhante, com intervalos de absorção distintos de acordo com materiais típicos desses elementos estruturais.
                Dessa forma, o código gerou automaticamente um conjunto de parâmetros realistas para diferentes configurações de salas, permitindo a simulação de ambientes acústicos diversos com base nas propriedades físicas de suas superfícies.
                PAREI NO PRIMEIRO CODIGO
                Com o objetivo final de desenvolver uma abordagem para a estimativa cega de parâmetros acústicos, este estágio inicial, de natureza experimental e exploratória, consistiu em implementar um modelo RESNET-50 para estimar as seguintes variáveis:
            </p>
            <ul>
               <li>Área Superficial (m²)</li>
               <li>Volume (m³)</li>
               <li>Superfície 1 (m²)</li>
               <li>Superfície 2 (m²)</li>
               <li>Superfície 3 (m²)</li>
               <li>Superfície 4 (m²)</li>
               <li>Superfície 5 (m²)</li>
               <li>Superfície 6 (m²)</li>
               <li>Absorção Média (125 Hz)</li>
               <li>Absorção Média (250 Hz)</li>
               <li>Absorção Média (500 Hz)</li>
               <li>Absorção Média (1000 Hz)</li>
               <li>Absorção Média (2000 Hz)</li>
               <li>Absorção Média (4000 Hz)</li>
               <li>T60_Sabine_125</li>
               <li>T60_Sabine_250</li>
               <li>T60_Sabine_500</li>
               <li>T60_Sabine_1000</li>
               <li>T60_Sabine_2000</li>
               <li>T60_Sabine_4000</li>
            </ul>
            <p>O resultado preliminar encontra-se no seguinte link: <a href="link-resultados" target="_blank">Resultados</a>.</p>
            <p>O modelo treinado encontra-se no seguinte link: <a href="link-modelo" target="_blank">Modelo Treinado</a>.</p>
            
            <h4>Características do Modelo</h4>
            <ul>
                <li>Base: ResNet-50 pré-treinada (ImageNet).</li>
                <li>Camadas finais removidas (mantendo apenas a extração de características).</li>
                <li>Camadas adicionais: 
                    <ul>
                        <li>Global Average Pooling (reduzindo a saída para 2048 neurônios).</li>
                        <li>Uma cabeça para predição dos valores esperados (mu_head).</li>
                        <li>Uma cabeça para predição da incerteza (sigma_head), ativada com Softplus.</li>
                    </ul>
                </li>
            </ul>

            <h4>Função de Perda - Log-Verossimilhança Gaussiana</h4>
            <p>
                O modelo utiliza uma função de perda baseada em distribuição Gaussiana para estimar a incerteza da predição. A equação utilizada é:
            </p>
            <pre>
L = 0.5 * Σ (log(σ²) + ((y - μ)² / σ²))
            </pre>
            <p>Essa abordagem permite que o modelo aprenda não apenas os valores das variáveis acústicas, mas também o nível de incerteza associado às predições.</p>

            <h4>Hiperparâmetros do Treinamento</h4>
            <ul>
                <li>Épocas: 50</li>
                <li>Otimizador: Adam (lr=1e-5)</li>
                <li>Divisão dos Dados: 80% Treino, 20% Validação</li>
                <li>Checkpoint: Salvo a cada época</li>
                <li>GPU utilizada: NVIDIA T4</li>
            </ul>

            <h4>Treinamento e Validação</h4>
            <p>
                Durante o treinamento, o modelo foi avaliado em cada época utilizando a função de perda de log-verossimilhança Gaussiana. O progresso do treinamento e validação foi registrado, gerando um gráfico de perdas ao longo das épocas.
            </p>
            <ul>
                <li>Acurácia no treino: X%</li>
                <li>Erro de treino: Y</li>
                <li>Erro de validação: Z</li>
                <li>Acurácia no teste: W%</li>
                <li>Erro no teste: V</li>
            </ul>

            <h4>Visualização das Perdas</h4>
            <p>O gráfico abaixo mostra a evolução da perda durante o treinamento:</p>
            <img src="link-grafico" alt="Gráfico de Treinamento e Validação" style="width: 100%; max-width: 600px;">
        </div>

        <!-- Espaço reservado para Projeto 2 -->
        <div class="projeto">
            <h3><a href="link-projeto-2" target="_blank">Projeto 2</a></h3>
            <p>
                Descrição do Projeto 2. Este espaço pode ser preenchido com detalhes sobre o segundo projeto, incluindo seu objetivo, tecnologias utilizadas e resultados obtidos.
            </p>
            <p>Mais informações podem ser encontradas no seguinte link: <a href="link-resultados-2" target="_blank">Resultados do Projeto 2</a>.</p>
        </div>

        <!-- Espaço reservado para Projeto 3 -->
        <div class="projeto">
            <h3><a href="link-projeto-3" target="_blank">Projeto 3</a></h3>
            <p>
                Descrição do Projeto 3. Este espaço pode ser preenchido com detalhes sobre o terceiro projeto, explicando sua relevância, metodologia aplicada e conclusões alcançadas.
            </p>
            <p>Mais informações podem ser encontradas no seguinte link: <a href="link-resultados-3" target="_blank">Resultados do Projeto 3</a>.</p>
        </div>

    </section>

  
    
    <section id="artigos">
        <h2>Artigos Publicados</h2>
        <div class="artigo">
            <h3>Unreal Engine 5 Simulations of Solar Plant Inspections by Unmanned Aerial Systems with Robot Operating System 2</h3>
            <p><strong>Autores:</strong> Fabio Andrade, Agnar Sivertsen, Marcos G L Moura, Lucas Cavalcante Clarino, Gabriel Souza Machado Gonzaléz, Luis Paulo Albuquerque Guedes, Carlos Alberto Correia, Mariane Petraglia, Alessandro Rosa Lopes Zachi </p>
            <p><strong>Resumo:</strong> Este artigo apresenta um sistema de simulação de alta fidelidade para inspeção de usinas solares utilizando Sistemas Aéreos Não Tripulados. Ele integra o Unreal Engine 5 para visuais realistas, o AirSim para simulação da física e sensores de drones e o Robot Operating System 2 para desenvolvimento de algoritmos. O sistema permite testar algoritmos de inspeção em um ambiente virtual realista, aprimorando o desenvolvimento de soluções de visão computacional e detecção de objetos. Um estudo de caso utilizando a Unidade de Controle de Voo ArduPilot, Detecção de Bordas de Canny e controle PID demonstra sua eficácia.</p>
            <p><a href="link-artigo" target="_blank">Acesse o artigo completo</a></p>
        </div>
        <div class="artigo">
            <h2>Radio Frequency-Audio Based Drone Classification using Deep Learning Methods</h2>
            <p><strong>Autores:</strong> Luis Paulo Albuquerque Guedes, Mariane Petraglia, Rêmulo M. Caminha Gomes</p>
            <p><strong>Resumo:</strong> Este artigo propõe um modelo de aprendizado profundo que utiliza a fusão de dados de sensores acústicos e de radiofrequência (RF) para a classificação de Veículos Aéreos Não Tripulados (UAVs). O modelo visa aumentar a precisão na classificação de diferentes tipos de drones, garantindo redundância para evitar falhas. O trabalho foi estruturado em três etapas: análise acústica para classificação de tipos de drones (etapa 1), classificação baseada em assinaturas de RF (etapa 2) e integração dos sensores (etapa 3). A combinação de sensores acústicos e de RF resultou em uma melhoria significativa no desempenho da classificação de drones, aumentando a precisão de 0.8342 para 0.8617. Além disso, o uso dessa fusão de dados melhorou a precisão em até 15,3% em faixas de SNR mais baixas.</p>
            <p><a href="link-artigo" target="_blank">Acesse o artigo completo</a></p>
        </div>
        <div class="artigo">
            <h2>An Integrated Framework for UAV Sound Tracking and Classification Using Deep Learning Techniques and Kalman Filters</h2>
            <p><strong>Autores:</strong> Luis Paulo Albuquerque Guedes, Mariane Petraglia, Pedro Henrique Monteiro Guedes</p>
            <p><strong>Resumo:</strong> Este artigo apresenta um framework integrado que combina classificação acústica e rastreamento de trajetória de Veículos Aéreos Não Tripulados (UAVs) utilizando técnicas de aprendizado profundo e filtros de Kalman. A abordagem proposta visa melhorar a precisão na identificação do tipo de UAV e na predição de trajetória, com base em dados acústicos passivos reais registrados em uma câmara anecoica e convolvidos com ruído ambiental. Os resultados das simulações confirmaram a eficácia do sistema tanto nas tarefas de classificação quanto na estimativa de trajetória. Para a classificação do tipo de UAV, o F1-score geral atingiu 0.8342, com o Drone C obtendo o melhor desempenho (0.8504). Para a classificação da direção de manobra, os Drones A e B alcançaram um F1-score de 0.8277, enquanto o Drone C obteve 0.8298. O erro médio de distância na estimativa de trajetória foi de aproximadamente 8 metros, com desvios padrão variando de 3.34 a 3.55 metros, demonstrando consistência e precisão em todas as dimensões avaliadas.</p>
            <p><a href="link-artigo" target="_blank">Acesse o artigo completo</a></p>
        </div>

    </section>

        <section id="contato">
        <h2>Contato</h2>
        <ul>
            <li>
                <img src="email-icon.png" alt="Email" width="20"> 
                <a href="mailto:luis.albuquerque@marinha.mil.br">luis.albuquerque@marinha.mil.br</a>
            </li>
            <li>
                <img src="email-icon.png" alt="Email" width="20"> 
                <a href="mailto:luis.guedes@coppe.ufrj.br">luis.guedes@coppe.ufrj.br</a>
            </li>
            <li>
                <img src="email-icon.png" alt="Email" width="20"> 
                <a href="mailto:luispauloaguedes@gmail.com">luispauloaguedes@gmail.com</a>
            </li>
            <li>
                <img src="github-icon.png" alt="GitHub" width="20"> 
                <a href="https://github.com/seuusuario" target="_blank">GitHub</a>
            </li>
            <li>
                <img src="linkedin-icon.png" alt="LinkedIn" width="20"> 
                <a href="https://www.linkedin.com/in/seuperfil" target="_blank">LinkedIn</a>
            </li>
        </ul>
    </section>

    <script>
        function translate(language) {
            if (language === 'en') {
                window.location.href = "pagina-ingles.html";
            } else if (language === 'de') {
                window.location.href = "pagina-alemao.html";
            }
        }
    </script>

</body>
</html>




</body>
</html>



